# %%

import pandas as pd

df = pd.read_excel("data/dados_cerveja_nota.xlsx")
df.head()
# %%
from sklearn import linear_model
from sklearn import tree

X = df[['cerveja']] # Isso √© uma matriz (df)
y = df['nota'] # isso √© um vetor (series)

# Isso aqui √© o modelo, aprendizado de maquina
"""
linear_model.LinearRegression:
Ele cria um modelo de regress√£o linear, que √© um dos algoritmos mais b√°sicos e importantes de aprendizado de m√°quina supervisionado.

üëâ Em resumo, ele:

- Ajusta uma reta (ou hiperplano, no caso de m√∫ltiplas vari√°veis) aos dados para modelar a rela√ß√£o entre vari√°veis independentes (X) e a vari√°vel dependente (y).
- Calcula os coeficientes (pesos) e o intercepto que melhor explicam a rela√ß√£o entre as vari√°veis, minimizando o erro quadr√°tico m√©dio (MSE).
- Depois, pode ser usado para fazer previs√µes em novos dados.
"""
reg = linear_model.LinearRegression(fit_intercept=True)

"""
.fit() no scikit-learn √© sempre usado para treinar/ajustar o modelo aos dados.

No caso de LinearRegression, ele faz o seguinte:
- Recebe os dados de entrada (X) ‚Üí as vari√°veis independentes (features).
- Recebe o alvo (y) ‚Üí a vari√°vel dependente (o que voc√™ quer prever).
- Calcula os coeficientes (pesos) e o intercepto que melhor se ajustam aos dados, minimizando o erro quadr√°tico m√©dio (m√©todo dos m√≠nimos quadrados).
- Armazena esses valores dentro do objeto do modelo (reg.coef_ e reg.intercept_).
"""
reg.fit(X,y)

# Aqui a gente descobre qual o valor de A e B 
# Da formula f(x) = a + bx
a,b = reg.intercept_, reg.coef_[0]

# Aqui estamos prevendo y com base em X
predict_reg = reg.predict(X.drop_duplicates())


# Aqui fazemos para a arvore de decis√£o
# Aqui ela est√° ajustada 100% em cima dos dados
arvore_full = tree.DecisionTreeRegressor(random_state=42)
arvore_full.fit(X,y)
predict_arvore_full = arvore_full.predict(X.drop_duplicates())

# Aqui fazemos para a arvore de decis√£o
# Aqui voc√™ est√° limitando at√© onde a arvore vai quebrar
arvore_d2 = tree.DecisionTreeRegressor(random_state=42, 
                                       max_depth=2)
arvore_d2.fit(X,y)
predict_arvore_d2 = arvore_d2.predict(X.drop_duplicates())

# %%

import matplotlib.pyplot as plt

# Plotamos a predi√ß√£o
plt.plot(X['cerveja'], y, 'o')
plt.grid(True)
plt.title("Rela√ß√£o Cerveja vs Nota")
plt.xlabel("Cerveja")
plt.ylabel("Nota")
plt.plot(X.drop_duplicates()['cerveja'],
         predict_reg)

plt.plot(X.drop_duplicates()['cerveja'],predict_arvore_full)
plt.plot(X.drop_duplicates()['cerveja'],predict_arvore_d2)

plt.legend(['Observado', 
            f'y = {a:.3f} + {b:.3f}x',
            'Arvore Full',
            'Arvore Depth = 2'])
plt.show()
# %%

plt.figure(dpi=400)
tree.plot_tree(arvore_d2,
               feature_names=['cerveja'],
               filled=True)
# %%
